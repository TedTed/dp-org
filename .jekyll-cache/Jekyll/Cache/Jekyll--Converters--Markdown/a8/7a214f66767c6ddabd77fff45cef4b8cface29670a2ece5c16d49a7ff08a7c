I"±<p>Differential privacy protects against extremely strong adversaries‚Äîeven ones who know the entire dataset except for one bit of information about one individual.  Since its inception, people have considered ways to relax the definition to assume a more realistic adversary.  A natural way to do so is to incorporate some distributional assumptions. That is, rather than considering a worst-case dataset, assume the dataset is drawn from some distribution and provide some form of ‚Äúaverage-case‚Äù or ‚ÄúBayesian‚Äù privacy guarantee with respect to this distribution. This is especially tempting as it is common for statistical analysis to work under distributional assumptions.</p>
:ET